---
layout: post
cid: 51
title: 我教我自己：Storm技术内幕与大数据实践（一）
slug: 51
date: 2021/04/13 17:45:10
updated: 2021/04/13 17:45:10
status: publish
author: AntiTopQuark
categories: 
  - Storm
  - 大数据
tags: 
  - 节点
  - 逻辑
  - 函数
  - 接口
  - 变量
  - 程序
  - 方法
  - 分配
  - 语言
  - 数据库
  - 系统
  - 完整性
  - 事务
  - 用户
  - 状态
  - 进程
  - 对象
  - 分区
  - 任务
  - 数据
  - 操作
  - task
  - 机器
  - 过程
  - worker
  - 架构
  - 开发
  - 处理
  - 1.1.1
  - 计算
  - partition
  - storm
  - tuple
  - bolt
  - 问题
  - 编程
customSummary: 
noThumbInfoStyle: default
outdatedNotice: no
reprint: standard
thumb: 
thumbChoice: default
thumbDesc: 
thumbSmall: 
thumbStyle: default
---


<!-- index-menu -->
# 第一章 绪论
Apache Storm（ http://storm.apache.org/ ）是由 Twitter 开源的分布式实时计算系统。Storm 可以非常容易并且可靠地处理无限的数据流。对比 Hadoop 的批处理，Storm 是一个实时的、分布式的、具备高容错的计算系统。Storm 应用可以使用何编程语言来进行开发。
## 1.1 Storm 基本组件
### 1.1.1 集群组成
在 Storm 的集群中有两种节点：主节点（Master Node）**Nimbus** 和工作节点（Worker Node）**Supervisor**。
**Nimbus** 的作用：用于提交应用 Topology、管理整个 Storm 节点（将 Topology 的 Task 分配给 Worker、监控各个 Supervisor 节点的状态进行负载均衡等）。Nimbus 节点上不能运行 Worker。

每个工作节点上运行一个 Supervisor 进程（类似于 TaskTracker）。Supervisor 会监听 Nimbus 分配给那台机器的工作，根据需要启动/关闭具体的 Worker 进程。
每个 Worker 进程执行一个具体的 Topology，Worker 进程中的执行线程称为 Executor，可以有一个或者多个。每个 Executor 中又可以包含一个或者多个 Task。Task 为 Storm 中最小的处理单元。一个运行的 Topology 由运行在一台或者多台工作节点上的 Worker 进程来完成具体的业务执行。

Storm 组件和 Hadoop 组件的对比
![45542-e4gf4mpdek.png](http://www.sukidesu.top/usr/uploads/2020/03/773675356.png)

Nimbus 和 Supervisor 之间的通信依靠 ZooKeeper 完成，并且 Nimbus 进程和 Supervisor 都是快速失败（fail-fast）和无状态的，所有的状态要么在 ZooKeeper 里面，要么在本地磁盘上。

> 迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。每当迭代器使用 hashNext()/next() 遍历下一个元素之前，都会检测 modCount 变量是否为 expectedModCount 值，是的话就返回遍历；否则抛出异常，终止遍历。


这也就意味着你可以用kill -9来杀死 Nimbus 和 Supervisor 进程，然后再重启它们，它们可以继续工作，就好像什么都没有发生过似的。这个设计使得 Storm 具有非常高的稳定性。

Storm 的基本体系架构
![76338-jdpgvsrhpfa.png](http://www.sukidesu.top/usr/uploads/2020/03/4197502868.png)

### 1.1.2 核心概念
组件| 概念 
-|-|-
Topology | 一个实时计算应用程序逻辑上被封装在 Topology 对象中，类似 Hadoop 中的作业。与作业不同的是，Topology 会一直运行直到显式地杀死它 
Nimbus | 负责资源分配和任务调度，类似 Hadoop 中的 JobTracker 
Supervisor | 负责接受 Nimbus 分配的任务，启动和停止属于自己管理的 Worker 进程，类似 Hadoop 中的 TaskTracker 
Worker | 运行具体处理组件逻辑的进程 
Executor | Storm 0.8 之后，Executor 为 Worker 进程中的具体的物理线程，同一个 Spout/Bolt 的 Task 可能会共享一个物理线程，一个 Executor 中只能运行隶属于同一个 Spout/Bolt 的 Task 
Task | 每一个 Spout/Bolt 具体要做的工作，也是各个节点之间进行分组的单位 
Spout | 在 Topology 中产生源数据流的组件。通常 Spout 获取数据源的数据（如 Kafka、MQ 等读取数据），然后调用 nextTuple 函数，发射数据供 Bolt 消费，参见图 1-3 
Bolt | 在 Topology 中接受 Spout 的数据然后执行处理的组件。Bolt 可以执行过滤、函数操作、合并、写数据库等任何操作。Bolt 在接收到消息后会调用 execute 函数，用户可以在其中执行自己想要的操作，参见图 1-4 
Tuple | 消息传递的基本单元 
Stream | 源源不断传递的 Tuple 组成了 Stream 
Stream 分组 | 即消息的分区（partition）方法。Storm 中提供若干种实用的分组方式，包括 Shuffle、Fields、All、Global、None、Direct 和 Local or shuffle 等
![51287-nkys4nag2cp.png](http://www.sukidesu.top/usr/uploads/2020/03/1161311844.png)

![13761-is71llnm2n8.png](http://www.sukidesu.top/usr/uploads/2020/03/1020618145.png)

在 Storm 中有 7 种内置的分组方式，也可以通过实现CustomStreamGrouping接口来定义自己的分组。 
（1）Shuffle 分组：Task 中的数据随机分配，可以保证同一级 Bolt 上的每个 Task 处理的 Tuple 数量一致，如图 1-5 所示。 图 1-5　
![86191-yacixv65o5j.png](http://www.sukidesu.top/usr/uploads/2020/03/3170285701.png)
（2）Fields 分组：根据 Tuple 中的某一个 Filed 或者多个 Filed 的值来划分。比如 Stream 根据 user-id 的值来分组，具有相同 user-id 值的 Tuple 会被分发到相同的 Task 中，如图 1-6 所示。
（具有不同 user-id 值的 Tuple 可能会被分发到其他 Task 中。比如 user-id 为 1 的 Tuple 都会分发给 Task1，user-id 为 2 的 Tuple 可能在 Task1 上也可能在 Task2 上，但是同时只能在一个 Task 上。） 
![73279-dhqun2sqyb.png](http://www.sukidesu.top/usr/uploads/2020/03/1191229986.png)
（3）All 分组：所有的 Tuple 都会到分发到所有的 Task 上，如图 1-7 所示。   
![61982-lxfjpyowc.png](http://www.sukidesu.top/usr/uploads/2020/03/3946101656.png)
（4）Global 分组：整个 Stream 会选择一个 Task 作为分发的目的地，通常是具有最新 ID 的 Task，如图 1-8 所示。   ![52774-znjmvu92bnq.png](http://www.sukidesu.top/usr/uploads/2020/03/3654633864.png) 
（5）None 分组：也就是你不关心如何在 Task 中做 Stream 的分发，目前等同于 Shuffle 分组。 
（6）Direct 分组：这是一种特殊的分组方式，也就是产生数据的 Spout/Bolt 自己明确决定这个 Tuple 被 Bolt 的哪些 Task 所消费。如果使用 Direct 分组，需要使用 OutputCollector 的 emitDirect 方法来实现。 
（7）Local or shuffle 分组：如果目标 Bolt 中的一个或者多个 Task 和当前产生数据的 Task 在同一个 Worker 进程中，那么就走内部的线程间通信，将 Tuple 直接发给在当前 Worker 进程中的目的 Task。否则，同 Shuffle 分组。
### 1.1.3 Storm 的可靠性
Storm 允许用户在 Spout 中发射一个新的 Tuple 时为其指定一个 MessageId，这个 MessageId 可以是任意的 Object 对象。多个 Stream Tuple 可以共用同一个 MessageId，表示这多个 Stream Tuple 对用户来说是同一个消息单元。Storm 的可靠性是指 Storm 会告知用户每一个消息单元是否在一个指定的时间内被完全处理。完全处理的意思是该 MessageId 绑定的 Stream Tuple 以及由该 Stream Tuple 衍生的所有 Tuple 都经过了 Topology 中每一个应该到达的 Bolt 的处理。在 Storm 中，使用 Acker 来解决 Tuple 消息处理的可靠性问题。
### 1.1.4 Storm特性
- 易用性 开发非常迅速，容易上手。
- 容错性 Storm 的守护进程（Nimbus、Supervisor 等）都是无状态的，状态保存在 ZooKeeper 中，可以随意重启。
- 扩展性 当某一级处理单元速度不够，可以直接配置并发数，即可线性地扩展性能。
- 完整性 采用 Acker 机制，保证数据不丢失；采用事务机制，保证数据准确性。



