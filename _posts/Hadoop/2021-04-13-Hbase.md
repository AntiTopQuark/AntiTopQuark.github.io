---
layout: post
cid: 58
title: Hbase
slug: 58
date: 2021/04/13 17:49:21
updated: 2021/04/13 17:49:21
status: publish
author: AntiTopQuark
categories: 
  - Hadoop
  - 大数据
tags: 
  - 类型
  - 逻辑
  - 接口
  - 分配
  - 语言
  - 内存
  - 数据库
  - 系统
  - 存储
  - 事务
  - 用户
  - 状态
  - 对象
  - 文件
  - hbase
  - 写入
  - region
  - 数据
  - hfile
  - 客户端
  - 模型
  - 流程
  - 架构
  - 水平
  - 索引
  - 服务器
  - 概述
  - 日志
  - 组织
  - 表
  - 锁
  - log
  - 字符
  - key
  - compaction
  - 处理
  - 计算
  - 步骤
  - 编程
customSummary: 
noThumbInfoStyle: default
outdatedNotice: no
reprint: standard
thumb: 
thumbChoice: default
thumbDesc: 
thumbSmall: 
thumbStyle: default
---



<!-- index-menu -->
# 概述
HBase是一个构建在Hadoop之上的高可用、高性能、多版本的分布式NOSQL数据库。
HBase是Google Bigtable的开源实现，通过在廉价服务器上搭建大规模结构化存储集群，提供海量数据高性能的随机读写能力。
![77650-alnqli833fh.png](http://www.sukidesu.top/usr/uploads/2020/03/3422933834.png)
HBase位于结构化存储层，
- Hadoop HDFS为HBase提供了高可靠性的底层存储支持， 
- MapReduce等为HBase提供了高性能 的计算能力， 
- Zookeeper为HBase提供了稳定服务和failover机制。 
- phoenix和Hive等还为HBase提供了高层语言支持，使得在HBase上进行数据统计处理变的非常简单。 
- Sqoop等则为HBase提供了方便的RDBMS数据 导入功能，使得传统数据库数据向HBase中迁移变的非常方便。
![13847-ovqrglqj7ch.png](http://www.sukidesu.top/usr/uploads/2020/03/1241226645.png)
# 数据模型
- 从逻辑视图来说，HBase中的数据是以表形式进行组织的，而且和关系数据库中的一 样，HBase中的表由行和列构成，因此HBase非常容易理解。
- 从物理视图来说，HBase是一个Map，由键值对组成，不过和普通的Map不同， HBase是一个稀疏的、分布式的、多维排序的Map。
## 逻辑视图
![61932-ko6d3gp92ls.png](http://www.sukidesu.top/usr/uploads/2020/03/3519265594.png)
**rowkey** 

- row key是用来检索记录的主键。访问hbase table中的行，只有三种方式：通过单个row key访问；通过row key的 range；全表扫描。 
- row key行键 (Row key)可以是任意字符串(最大长度是 64KB，实际应用中长度一般为 10-100bytes)，在hbase内部， row key保存为字节数组。 
- 存储时，数据按照Row key的字典序(byte order)排序存储。设计key时，要充分利用排序存储这个特性，将经常一起读取的行存储放到一起。 

**列簇(column family)** 

- hbase表中的每个列，都归属与某个列簇。 
- 列簇是表的schema的一部分(而列不是)，必须在使用表之前定义。 
- 列名都以列簇作为前缀。

**单元(cell)**

- HBase中通过row和columns确定的为一个存贮单元称为cell。 
- cell中的数据是没有类型的，全部是字节码形式存贮。 

**时间戳(timestamp)** 

- 每个cell都保存着同一份数据的多个版本。 
- 版本通过时间戳来索引。 
- 时间戳可以由hbase(在数据写入时自动 )赋值，此时是精确到毫秒的当前系统时间。也可以由客户显式赋值。 
- 每个cell中，不同版本的数据按照时间倒序排序，即最新的数据排在最前面。 
- hbase提供了两种数据版本回收方式。一是保存数据的最后n个版本，二是保存最近一段时间内的版本（比如最近七天）。

物理结构
![43560-87c2pjud28.png](http://www.sukidesu.top/usr/uploads/2020/03/2921862617.png)

## 为什么要有列族?
一行有若干列组成,若干列又构成一个列族（column family），这不仅有助于构建数据的语义边界或者局部边界，还有助于给他们设置某些特性（如压缩），或者指示他们存贮在内存中，一个列族的所有列存贮在同一个底层的存储文件中，这个存储文件叫做HFile。​ 
# Hbase架构
![87179-m57mm0g1oel.png](http://www.sukidesu.top/usr/uploads/2020/03/1124171799.png)

## 客户端
提供Shell命令行接口、原生Java API编程接口、Thrift/Rest API编程接口以及MapReduce 编程接口。 
HBase访问数据之前，首先通过元数据表定位目标数据所在的RegionServer，之后才会 发送请求到RegionServer。同时这些元数据会被缓存再客户端本地，以方便之后的请 求访问。如果集群RegionServer发生宕机或者执行了负载均衡等，从而导致数据分片 发生的迁移，客户端需要重新请求最新的元数据并缓存至本地。

## HMaster
- 处理用户的管理请求，例如：用户的增删改查等操作。 
- 协调RegionServer 
- 为RegionServer分配Region。 
- 发现失效的RegionServer并重新分配其上的Region。 
- 监控集群上所有RS的健康状态(通过zk)。 
- 清理过期日志以及文件(Hlog和HFile)。

##RegionServer
- 响应用户I/O请求,向HDFS文件系统中读写数据 。 
- 内部管理了一系列HRegion对象。 
- 每个HRegion对应了Table中的一个Region，HRegion中由多个HStore组成。 
- 每个HStore对应了Table中的一个Column Family的存储。 
- HFile: HBase中KeyValue数据的存储格式， HFile是Hadoop的二进制格式文件。 
- HRegionServer中都包含一个WAL(write a head log)。用于保存还未持久化存储的数据，用户数据的还原。 
- RS用于切分过大的Region。

WAL(HLog)在HBase中起两个核心作用。 
- 实现数据的高可靠性：HBase数据写入并非直接写入HFile，而是先写入缓存，再异步刷新落盘。为防止数据丢失，数据写入缓存之前需要首先写入Hlog，这样，即使缓存数据丢失，仍然可以通过 Hlog日志恢复。 
- 用于实现HBase集群件数据同步：通过回放主机群推送过来的Hlog日志来实现主从集群件数据的同步。 

BlockCache是HBase的读缓存，每个RS对应一个BlockCache。 
- 客户端从磁盘读取数据之后通常会将数据缓存到系统内存中，后续访问同一行数据可直接从内存中获取，对于大量热点读的业务请求来说，带来了极大的性能提升。 
- BlockCache缓存的对象是一系列的Block块(64KB)。由物理上相邻的多个KV组成。当前BlockCache主 要由两种实现：LRUBlockCache和BucketCache，后者在GC优化方面有明显的提升。

## Regin
HBase使用RowKey将表“水平切割”成多个Region，Region代表的是数据表的一个分片，也是集群负载均衡的基本单位，通常一张表的Region会分布在整个集群的多个RS上，一个RS上会存在多个Region， 当然这些Region一般来自不同的数据表。 
从HMaster的角度，每个 HRegion都纪录了它的StartKey 和EndKey。由于RowKey是排序的，因而Client可以通过 HMaster快速的定位每个 RowKey在哪个HRegion中。 
每个HRegionServer可以同时管理1000个左右的HRegion

## Zk
ZK管理着HBase的核心元数据，如：HMaster和HRegionServer的状态(available/alive等)，元数据表所在的 RS地址等 。 
ZK提供了宕机时通知功能，从而实现Hmaster的failover机制，RegionServer的failover机制。 
实现分布式表锁
![96605-x44u8qcnx8i.png](http://www.sukidesu.top/usr/uploads/2020/03/714476151.png)

# Hbase的优劣点
![08775-z9liwp11jp.png](http://www.sukidesu.top/usr/uploads/2020/03/2209863966.png)
![83415-n5coz4yft5q.png](http://www.sukidesu.top/usr/uploads/2020/03/1188616674.png)

# Hbase 写流程
写入流程概括为三个阶段 
- 客户端处理阶段 客户端将用户的写入请求进行预处理，并根据集群元数据定位写入数据所在的RegionServer，将请求发送给对应的regionServer。 
- Region写入阶段 RegionServer接收到写入请求之后将数据解析出来，首先写入WAL(Hlog)，再写入对应的region列簇的 MemStore。 
- MemStore Flush阶段 当Region中的MemStore容量超过一定阈值，系统会异步执行flush操作，将内存中的数据写入文件，形成HFile

![18780-86wjjvezz2.png](http://www.sukidesu.top/usr/uploads/2020/03/3959640359.png)

## 客户端处理阶段
步骤1 用户提交Put请求后，HBase客户端会将写入的数据添加到本地缓冲区中，符合一定条件就异步批量提交(默认utoflush=true时，请求直接提交给服务器处理。 
步骤2 客户端到hbase:meta中根据rowkey找到它们归属的RegionServer。批量请求时会把这些rowkey按照不同的regionServer分组。 
![34150-450ekygmxsk.png](http://www.sukidesu.top/usr/uploads/2020/03/4075876457.png)
步骤3 客户端发送RPC请求给对应的RegionServer

## Region写入阶段 
步骤1 RS收到写入请求后，首先反序列化put对象，执行各种检查(region是否只读，Memstore是否超过指定大小等)。 
步骤2 执行写入操作。
1.建立行锁(Acquire locks)->2.更新写入时间->3.创建WAL edit对象->4.WAL edit写入Hlog->5.数据写入MemStore->6.释放行锁->7.刷写Hlog到HDFS->8.结束事务
![06583-gy61msqoebw.png](http://www.sukidesu.top/usr/uploads/2020/03/3219677983.png)
# Hbase（第一次）读流程
![19490-7hj0t305djc.png](http://www.sukidesu.top/usr/uploads/2020/03/14465173.png)
# Compaction
随着Hfile文件数量的不断增多，查询可能需要越来越多的IO操作，读取延迟会越来越大。
执行Compaction会使文件个数基本稳定，进而读取IO的次数比较稳定，延迟就会稳定在一定范围。
Compaction操作重写文件会带来很大的带宽压力。所以图中出现很大的毛刺，这是 因为compaction在执行的时 候占用系统资源导致业务读 取性能受到一定的波及。
![01290-uhsv16ee01g.png](http://www.sukidesu.top/usr/uploads/2020/03/269914750.png)

MINOR-COMPACTION
HBase会自动拾取一些较小的HFiles，并将它们重新写入一些较大的HFiles中。 Minor compaction不会处理已经Deleted或Expired的Cell.

MAJOR-COMPACTION
将Region上一个列族对应的多个Hfile合并为一个大的Hfile文件。 删除过期数据，被删除数据。 改善Hbase读取效率。 会引起磁盘IO和网络资源的紧缺。 可以被设置为周期执行

# Region Spilt
![68821-70y1ftp9e09.png](http://www.sukidesu.top/usr/uploads/2020/03/3840233356.png)

# 与Hive对比
![70074-s9s3nqr2an.png](http://www.sukidesu.top/usr/uploads/2020/03/3435292477.png)

# 宕机处理
![11568-herrjag6379.png](http://www.sukidesu.top/usr/uploads/2020/03/1513132411.png)
