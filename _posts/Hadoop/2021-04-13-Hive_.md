---
layout: post
cid: 56
title: Hive 
slug: 56
date: 2021/04/13 17:48:06
updated: 2021/04/13 17:48:06
status: publish
author: AntiTopQuark
categories: 
  - Hadoop
  - 大数据
tags: 
  - 接口
  - 程序
  - 方法
  - 编译
  - 语句
  - 语言
  - 内存
  - 数据库
  - 扩展
  - 引擎
  - 存储
  - 查询
  - 用户
  - 进程
  - Python
  - 文件
  - 分区
  - 任务
  - map
  - 数据
  - join
  - 记录
  - 框架
  - 协议
  - 客户端
  - 过程
  - 服务器
  - mysql
  - 表
  - null
  - 试题
  - 语法
  - 区别
  - 字符
  - key
  - 开发
  - 处理
  - 大数据
  - hive
  - 计算
  - 机器学习
  - reduce
  - top10
  - 问题
  - 编程
  - cluster
  - count
  - 算法
customSummary: 
noThumbInfoStyle: default
outdatedNotice: no
reprint: standard
thumb: 
thumbChoice: default
thumbDesc: 
thumbSmall: 
thumbStyle: default
---



# 简介
- Hive是构建在Hadoop之上的数据仓库平台。 
- Hive是SQL解析引擎，它将SQL语句转译为MapReduce作业，并在 Hadoop上运行。 
- Hive表是HDFS的文件目录，一个表对应一个目录名，如果有分区的话， 则分区值对应子目录。
# 体系结构

用户接口：
- CLI：Cli 启动的时候，会同时启动一个Hive 副本。 
- JDBC客户端：封装了Thrift,java应用程序，可以通过指定的主机和端口连接到在另一个进程中运行的hive服务器 
- ODBC客户端：ODBC驱动允许支持ODBC协议的应用程序连接到Hive。 

Thrift服务器 基于socket通讯，支持跨语言。Hive Thrift服务简化了在多编程语言中运行Hive的命令。绑定支持C++,Java,PHP,Python 和Ruby语言。

![60248-cjh5jhl5o5v.png](http://www.sukidesu.top/usr/uploads/2020/03/994454505.png)

解析器：

- 编译器:完成 HQL语句从词法分析、语法分析、编译、优化以及执行计划的生成。 
- 优化器:是一个演化组件，当前它的规则是：列修剪，谓词下压。 
- 执行器会顺序执行所有的Job。如果Task链不存在依赖关系，可以采用并发执行的方式执行Job。

元数据库：

Hive的数据由两部分组成：数据文件和元数据。元数据用于存放Hive库的基础信息，它存储在关系数据库中，如 mysql、derby。
元数据包括： 数据库信息、表的名字，表的列和分区及其属性，表的属性，表的数据所在目录等
![03352-4w13mhxe4mg.png](http://www.sukidesu.top/usr/uploads/2020/03/265721860.png)

# Hive运行机制

- 用户通过用户接口连接Hive,发布Hive SQL。 
- Hive解析查询并制定查询计划。 
- Hive将查询转换成MapReduce作业。 
- Hive在Hadoop上执行MapReduce作业

![41730-cxbaovq6bx.png](http://www.sukidesu.top/usr/uploads/2020/03/1522862894.png)

# Hive应用场景
优势：
- 解决了传统关系数据库在大数据处理上的瓶颈。适合大数据的批量处理。 
- 充分利用集群的CPU计算资源、存储资源，实现并行计算。 
- Hive支持标准SQL语法，免去了编写MR程序的过程，减少了开发成本。 
- 具有良好的扩展性，拓展功能方便。

缺点：
- Hive的HQL表达能力有限：有些复杂运算用HQL不易表达。 
- Hive效率低：Hive自动生成MR作业，通常不够智能；HQL 调优困难，粒度较粗；可控性差。 
- 针对Hive运行效率低下的问题，促使人们去寻找一种更快，更具交互性的分析框架。 SparkSQL 的出现则有效的提高了 Sql在Hadoop 上的分析运行效率。

适用场景： 海量数据的存储处理  数据挖掘  海量数据的离线分析 
不适用场景： 复杂的机器学习算法  复杂的科学计算  联机交互式实时查询
# Hive链接
- HiveServer2 
目前Hive的Thrift服务端通常使用HiveServer2,它是HiveServer改进版本，它提供了新的ThriftAPI来处 理JDBC或者ODBC客户端，可以进行Kerberos身份验证，支持多个客户端并发。 
- Beeline 
HiveServer2还提供了新的CLI：BeeLine，它是Hive 0.11引入的新的交互式CLI，基于SQLLine，可以 作为Hive JDBC Client 端访问HievServer2。 通过beeline连接hive：jdbc:hive2://192.168.88.104:10000/hiveTest 

# Hive与传统数据库的对比
![90592-qxti0fooju.png](http://www.sukidesu.top/usr/uploads/2020/03/1397347383.png)
# 托管表和外部表
![27702-u9j7z3fcxsc.png](http://www.sukidesu.top/usr/uploads/2020/03/3203540046.png)
# 分区和分桶
![78047-sx2zpes4fqs.png](http://www.sukidesu.top/usr/uploads/2020/03/4268994466.png)
Hive表分区分为两种，静态分区和动态分区。
静态分区和动态分区的区别在于导入数据时，是手动输入分区名称，还是通过数据来判断数据分区。对于大数据批量导入来说，显然采用动态分区更为简单方便。
![28974-6yw5mcrzl49.png](http://www.sukidesu.top/usr/uploads/2020/03/83223890.png)

# HIve表存储格式
![10187-pn7w1rrfdqo.png](http://www.sukidesu.top/usr/uploads/2020/03/2414194681.png)
![28628-x38av7q58fr.png](http://www.sukidesu.top/usr/uploads/2020/03/3513321909.png)

# 面试题
## 数据倾斜
数据倾斜就是数据的分布不平衡，某些地方特别多，某些地方又特别少，导致的在处理数据的时候，有些很快就处理完了，而有些又迟迟未能处理完，导致整体任务最终迟迟无法完成，这种现象就是数据倾斜。

**原因**

- key分布不均匀
- 业务数据本身的特性
- SQL语句造成数据倾斜

**解决方法**

1. hive设置hive.map.aggr=true和hive.groupby.skewindata=true
2. 有数据倾斜的时候进行负载均衡，当选项设定为true,生成的查询计划会有两个MR Job。第一个MRJob中，Map的输出结果集合会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；第二个MR Job在根据预处理的数据结果按照 Group By Key 分布到Reduce中(这个过程可以保证相同的 Group By Key 被分布到同一个Reduce中)，最后完成最终的聚合操作。
3. SQL语句调整:

- 选用join key 分布最均匀的表作为驱动表。做好列裁剪和filter操作，以达到两表join的时候，数据量相对变小的效果。
- 大小表Join： 使用map join让小的维度表（1000条以下的记录条数）先进内存。在Map端完成Reduce。
- 大表Join大表：把空值的Key变成一个字符串加上一个随机数，把倾斜的数据分到不同的reduce上，由于null值关联不上，处理后并不影响最终的结果。
- count distinct大量相同特殊值：count distinct时，将值为空的情况单独处理，如果是计算count distinct，可以不用处理，直接过滤，在做后结果中加1。如果还有其他计算，需要进行group by，可以先将值为空的记录单独处理，再和其他计算结果进行union.


## Hive中的排序关键字有哪些
sort by ：不是全局排序，其在数据进入reducer前完成排序
order by ：会对输入做全局排序，因此只有一个reducer(多个reducer无法保证全局有序).只有一个reducer,会导致当输入规模较大时，需要较长的计算时间。
cluster by ： 当distribute by 和sort by的字段相同时，等同于cluster by.可以看做特殊的distribute + sort
distribute by ：按照指定的字段对数据进行划分输出到不同的reduce中
## 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10
- 方案1:
在每台电脑上求出TOP10，可以采用包含10个元素的堆完成(TOP10小，用最大堆，TOP10大，用最小堆)。
比如求TOP10大，我们首先取前10个元素调整成最小堆，如果发现，然后扫描后面的数据，并与堆顶元素比较，如果比堆顶元素大，那么用该元素替换堆顶，然后再调整为最小堆。
最后堆中的元素就是TOP10大。
- 方案2
求出每台电脑上的TOP10后，然后把这100台电脑上的TOP10组合起来，共1000个数据
再利用上面类似的方法求出TOP10就可以了。
## 分区和分桶的区别
分区相当于子目录
分桶是食用hash值进行划分后，分入不同的桶中。
## Hive优化
通用设置
hive.optimize.cp=true：列裁剪
hive.optimize.prunner：分区裁剪
hive.limit.optimize.enable=true：优化LIMIT n语句
hive.limit.row.max.size=1000000：
hive.limit.optimize.limit.file=10：最大文件数


