---
layout: post
cid: 104
title: Presto 原理
slug: 104
date: 2021/04/19 02:47:26
updated: 2021/04/19 02:47:26
status: publish
author: AntiTopQuark
categories: 
  - 大数据
tags: 
  - 类型
  - 节点
  - 逻辑
  - 函数
  - 接口
  - 编译
  - 语句
  - 分配
  - 内存
  - 系统
  - 引擎
  - 存储
  - 查询
  - 用户
  - 任务
  - 数据
  - 操作
  - 机器
  - 过程
  - worker
  - 原理
  - 架构
  - 语法
  - key
  - 处理
  - 大数据
  - hive
  - 计算
  - 流水线
  - source
  - 问题
  - hash
  - presto
  - 执行
  - fragment
  - operator
customSummary: 
noThumbInfoStyle: default
outdatedNotice: no
reprint: standard
thumb: 
thumbChoice: default
thumbDesc: 
thumbSmall: 
thumbStyle: default
---


[TOC]

Presto 是 Facebook 推出的一个基于Java开发的大数据分布式 SQL 查询引擎，可对从数 G 到数 P 的大数据进行交互式的查询，查询的速度达到商业数据仓库的级别，据称该引擎的性能是 Hive 的 10 倍以上。Presto 可以查询包括 Hive、Cassandra 甚至是一些商业的数据存储产品，单个 Presto 查询可合并来自多个数据源的数据进行统一分析。Presto 的目标是在可期望的响应时间内返回查询结果，Facebook 在内部多个数据存储中使用 Presto 交互式查询，包括 300PB 的数据仓库，超过 1000 个 Facebook 员工每天在使用 Presto 运行超过 3 万个查询，每天扫描超过 1PB 的数据。

### Presto 架构

![img](https://image-bed113224.oss-cn-beijing.aliyuncs.com/img/1004194-20161107083330108-1194426772.png)

Presto查询引擎是一个Master-Slave的架构，由下面三部分组成:

1. 一个Coordinator节点：负责解析SQL语句，生成执行计划，分发执行任务给Worker节点执行
2. 一个Discovery Server节点：通常内嵌于Coordinator节点中
3. 多个Worker节点：负责实际执行查询任务,负责与数据源交互读取数据

Worker节点启动后向Discovery Server服务注册，Coordinator从Discovery Server获得可以正常工作的Worker节点。

如果配置了Hive Connector，需要配置一个Hive MetaStore服务为Presto提供Hive元信息

### Presto低延迟原理

- 完全基于内存的并行计算

- 流水线式计算作业
- 本地化计算
- 动态编译执行计划
- GC控制

### Presto存储插件

Presto设计了一个简单的数据存储的抽象层， 来满足在不同数据存储系统之上都可以使用SQL进行查询。

存储插件（连接器,connector）只需要提供实现以下操作的接口， 包括对元数据（metadata）的提取，获得数据存储的位置，获取数据本身的操作等。

除了我们主要使用的Hive/HDFS后台系统之外， 我们也开发了一些连接其他系统的Presto 连接器，包括HBase，Scribe和定制开发的系统

![img](https://images2015.cnblogs.com/blog/1004194/201611/1004194-20161107084550842-1772079215.png)

### presto执行过程

![image-20210419023843616](https://image-bed113224.oss-cn-beijing.aliyuncs.com/img/image-20210419023843616.png)

**Presto**包含三类角色，coordinator,discovery,worker。coordinator负责query的解析和调度。discovery负责集群的心跳和角色管理。worker负责执行计算。

1. **presto**-cli提交的查询，实际上是一个http POST请求。查询请求发送到coordinator后，经过词法解析和语法解析，生成抽象语法树，描述查询的执行。

2. 执行计划编译器，会根据抽象语法树，层层展开，把语法树所表示的结构，转化成由单个操作所组成的树状的执行结构，称为逻辑执行计划。

3. 原始的逻辑执行计划，直接表示用户所期望的操作，未必是性能最优的，在经过一系列性能优化和转写，以及分布式处理后，形成最终的逻辑执行计划。这时的逻辑执行计划，已经包含了map-reduce操作，以及跨机器传输中间计算结果操作。

   > 转写成逻辑执行计划的过程，包括转写和优化。把抽象语法树转写成由简单操作组成的结点树，然后把树中所有聚合计算节点转写成map-reduce形式。并且在map-reduce节点中间插入Exchange节点。然后，进行一系列优化，把一些能提前加速计算的节点下推，能合并的节点合并。
   >
   > 最后逻辑执行计划按照Exchange节点做划分，分成不同的段(fragament)，表示不同阶段的的执行计划。在调度时，按照fragment调度。

4. scheduler从数据的meta上获取数据的分布，构造split，配合逻辑执行计划，把对应的执行计划调度到对应的worker上。

   > 调度涉及到两个问题，第一，某个fragment分配由哪些机器执行；第二，某个fragment的计算结果如何输出到下游fragment。
   >
   > 在调度时，需要为每一个fragment指定分配到哪些机器上。从调度上划分，fragment分三种类型:
   >
   > 1. source类型 : 由原始数据的存储位置决定fragment调度机器,connector会根据数据的meta，决定需要读取多少个split(分片) ，对于每一个source节点，分配一个split到一台机器上
   > 2. FIXED类型，主要用于纯计算节点，从集群中选择一台或多台机器分配给某个fragment。选择机器的方式是随机选择。
   > 3. SINGLE类型，只有一台机器，主要用于汇总结果，随机选择一台机器。
   >
   > 对于计算结果输出，根据下游节点的机器个数，也有多种方式，
   >
   > - 如果下游节点有多台机器，例如group by的中间结果，会按照group by的key计算hash，按照hash值选择一个下游机器输出。对于非group by的计算，会随机选择或者round robin。
   > - 如果下游节点只有一台机器，会输出到这台机器上。

5. 在worker上，逻辑执行计划生成物理执行计划，根据逻辑执行计划，会生成执行的字节码，以及operator列表。operator交由执行驱动来完成计算。

   > 逻辑执行计划fragment发送到机器上后，由结点树形式转写成operator list，根据逻辑代码动态编译生成字节码。动态生成字节码，主要是利用编译原理：
   >
   > - 展开循环
   > - 根据数据列的类型，直接调用对用的函数，以减少分支跳转语句。
   >
   > 这些手段会更好的利用CPU的流水线。
   >
   > Operator list 以串联形式处理数据，前一个operator的结果作为下一个结果的输入，对于source类型的operator，每一次调用都会获取一份新的数据；对于Aggregate的operator，只有之前所有的operator都finish之后，才能获取输出结果。



### presto引擎对比

与hive、SparkSQL对比结果图![img](https://images2015.cnblogs.com/blog/1004194/201611/1004194-20161107110246155-560444169.png)

 