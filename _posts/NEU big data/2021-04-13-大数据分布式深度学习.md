---
layout: post
cid: 81
title: 大数据分布式深度学习
slug: 81
date: 2021/04/13 20:38:58
updated: 2021/04/13 20:38:58
status: publish
author: AntiTopQuark
categories: 
  - NEU big data
  - 大数据
tags: 
  - 节点
  - 函数
  - 接口
  - 程序
  - 方法
  - 内存
  - 扩展
  - 存储
  - 界面
  - 用户
  - 进程
  - Python
  - spark
  - 分区
  - 任务
  - 数据
  - 框架
  - 协议
  - 模型
  - 流程
  - 过程
  - worker
  - 原理
  - 架构
  - 分布式
  - 服务器
  - epoch
  - with
  - 参数
  - 梯度
  - 深度学习
  - 深度
  - 开发
  - 处理
  - 大数据
  - 计算
  - 机器学习
  - 推理
  - 编程
  - cluster
  - 算法
customSummary: 
noThumbInfoStyle: default
outdatedNotice: no
reprint: standard
thumb: 
thumbChoice: default
thumbDesc: 
thumbSmall: 
thumbStyle: default
---


# 为什么要进行分布式地训练？
一方面使不得已而为之，比如：数据量太大，数据无法加载或者模型太复杂，一个GPU放不下参数。
另一方面，可以使用分布式提高训练速度

# 分布式训练策略
1. 模型并行:用于模型过大的情况，需要把模型的不同层放在不同节点或者GPU上，计算效率不高，不常用。
2. 数据并行:把数据分成多份，每份数据单独进行前向计算和梯度更新，效率高，较常用。

# 分布式并行模式
1. 同步训练：所有进程前向完成后统一计算梯度，统一反向更新。
2. 异步训练：每个进程计算自己的梯度，并拷贝主节点的参数进行更新，容易造成错乱，陷入次优解。

# 分布式训练架构
## Parameter Server 参数服务器
集群中有一个parameter server和多个worker，server需要等待所有节点计算完毕统一计算梯度，在server上更新参数，之后把新的参数广播给worker。
![参数服务器架构](http://www.sukidesu.top/usr/uploads/2020/12/1889274752.png)

基本流程如下：
1. woker加载数据，进行训练,更新梯度
2. 将梯度上传到server
3. server进行聚合梯度并且更新参数
4. woker进行拉取最新的参数，进行下一次训练

## Ring All-Reduce
只有worker，所有worker形成一个闭环，接受上家的梯度，再把累加好的梯度传给下家，最终计算完成后更新整个环上worker的梯度（这样所有worker上的梯度就相等了），然后求梯度反向传播。比PS架构要高效。
![Ring All-Reduce 架构图](http://www.sukidesu.top/usr/uploads/2020/12/1741967030.png)

算法主要分两步：

1. scatter-reduce：会逐步交换彼此的梯度并融合，最后每个 GPU 都会包含完整融合梯度的一部分。
![scatter-reduce 第一次迭代](http://www.sukidesu.top/usr/uploads/2020/12/1757990585.png)
![scatter-reduce 第二次迭代](http://www.sukidesu.top/usr/uploads/2020/12/2625565810.png)
![scatter-reduce 第三次迭代](http://www.sukidesu.top/usr/uploads/2020/12/1475946890.png)
2. allgather：GPU 会逐步交换彼此不完整的融合梯度，最后所有 GPU 都会得到完整的融合梯度
![89716-29l90btf74.png](http://www.sukidesu.top/usr/uploads/2020/12/3545005899.png)

#分布式深度学习框架
## Elephas [https://github.com/maxpumperla/elephas][1]
Elephas是Keras的扩展，它使您可以使用Spark大规模运行分布式深度学习模型。 原理上，Elephas如下图所示：
![elephas原理][2]

Elephas使用Spark的RDD和Dataframe实现了一个架构在Keras之上的数据并行算法。Keras模型在Spark Driver上进行初始化，之后进行序列化，连同数据和广播模型参数一起发送给Spark Worker。Spark Worker对模型进行反序列化，然后训练数据块，并将训练后的梯度发回Driver,Driver上的优化器进行同步或者异步地更新梯度，之后更新主模型。
总结：
1. 使用十分简单，`spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')`一行代码就可以实现其功能
2. 有使用者发现Driver会出现存储数据失败的情况，在相同epoch下，准确率大幅度降低
3. 由于采用PS架构，Driver的内存要求比较高，官方要求至少1G内存

## TensorFlowOnSpark [https://github.com/yahoo/TensorFlowOnSpark][3]
TensorFlowOnSpark由Yahoo开发，用于在Yahoo私有云中的Hadoop集群上进行大规模分布式深度学习。
TensorFlowOnSpark具有一些重要的优势（请参阅我们的博客）：
- 只需不到10行代码更改即可轻松迁移现有TensorFlow程序。
- 支持所有TensorFlow功能：同步/异步训练，模型/数据并行性，推理和TensorBoard。
- 服务器到服务器直接通信在可用时可以更快地学习。
- 允许HDFS上的数据集以及由Spark推送或由TensorFlow推送的其他来源。
- 轻松与您现有的Spark数据处理管道集成。
- 轻松部署在云或本地以及CPU或GPU上。

![系统架构](http://www.sukidesu.top/usr/uploads/2020/12/1429218158.png)

总结：
1. TensorFlowOnSpark依然是使用参数服务器与数据并行的结构
2. IO耗费时间多，有用户反映For 10 epochs of training, it took about 8.5 hours on a Yarn-Spark cluster with 2 nodes and 2 GPU, but the I/O took more than 3 hours.

## dist-keras [https://github.com/cerndb/dist-keras][4]
dist-keras（DK）是在Apache Spark和Keras之上构建的分布式深度学习框架，其目标是使用分布式机器学习算法来显着减少培训时间。设计框架的方式是，开发人员可以轻松实现新的分布式优化器，从而使人们能够专注于研究和模型开发。

遵循大型分布式深度网络论文中所述的数据并行方法。在此范例中，模型的副本分布在多个“训练器”上，并且每个模型副本都将在数据集的不同分区上进行训练。每次梯度更新后，梯度（或所有网络权重，取决于实现细节）将与参数服务器通信。参数服务器负责处理所有Worker的梯度更新，并将所有梯度更新合并到单个主模型中，该模型将在训练过程完成后返回给用户。

总结：
1. 使用简单，功能少，主要是实现了分布式的optimizer
2. 个人开发，目前已经项目已经归档，不再活跃开发

## Horovod [https://github.com/horovod/horovod][5]
Horovod是Uber开源的又一个深度学习工具，它的发展吸取了Facebook "Training ImageNet In 1 Hour" 与百度 "Ring Allreduce" 的优点，可为用户实现分布式训练提供帮助。本文将简要介绍如何使用Horovod配合pytorch更高效地进行分布式训练。
![性能](http://www.sukidesu.top/usr/uploads/2020/12/2451863865.png)

总结：
1. Uber开发，社区活跃
2. 支持多个深度学习框架，TensorFlow以及Pytorch和Keras
3. horovod的分布式貌似只支持同步更新式的数据并行，模型并行和异步更新式的数据并行都不支持

## determined-ai [https://determined.ai/product/][6]
determined AI 是一个深度学习分布式训练平台，从算法上讲，determined架构在horovod上，使用horovod来进行深度学习。除此之外，使用更高级的超参数调整，从而找到更好的模型。借助智能的GPU调度功能，提高GPU调度效率提高性能。以及安装方便，图形界面功能齐全。
![25662-kp9t2lxr05.png](http://www.sukidesu.top/usr/uploads/2020/12/2073608594.png)
![01799-biwny1krkj5.png](http://www.sukidesu.top/usr/uploads/2020/12/3679474296.png)
## Angel [https://github.com/Angel-ML/angel][7]
Angel 是一个基于参数服务器（Parameter Server）理念开发的高性能分布式机器学习平台，它基于腾讯内部的海量数据进行了反复的调优，并具有广泛的适用性和稳定性，模型维度越高，优势越明显。 Angel 由腾讯和北京大学联合开发，兼顾了工业界的高可用性和学术界的创新性。

Angel 的核心设计理念围绕模型。它将高维度的大模型合理切分到多个参数服务器节点，并通过高效的模型更新接口和运算函数，以及灵活的同步协议，轻松实现各种高效的机器学习算法。

Angel 基于 Java 和 Scala 开发，能在社区的 Yarn 上直接调度运行，并基于 PS Service ，支持 Spark on Angel ，未来将会支持图计算和深度学习框架集成。
![00619-tfkqmytgdga.png](http://www.sukidesu.top/usr/uploads/2020/12/3605549686.png)
总结：
1. 国产，社区活跃，但是目前算法支持少。
2. 使用Scala进行编程，而不借助于Python的深度学习框架
3. 支持多个参数服务器模型

## BigDL
BigDL，是 Intel 开源的一个基于 Apache Spark 的分布式深度学习库。使用 BigDL ，用户可以将他们的深度学习应用程序作为标准的 Spark 程序，它可以直接运行在现有的 Spark 或 Hadoop 集群之上。
特性：

丰富的深度学习支持。BigDL 模仿 Torch，提供对深度学习的全方位支持，包括数值计算（通过Tensor）和高层次神经网络。此外，用户可以使用 BigDL 将预训练的 Caffe 或 Torch 模型加载到 Spark 程序中。

极其高的性能。为了达到高性能，BigDL 在每个 Spark 任务中使用 Intel MKL和多线程编程。因此，它比单节点 Xeon 上的开箱即用的 Caffe、Torch 或 TensorFlow 快几个数量级。

有效地横向扩展。 BigDL 可以通过利用 Apache Spark 以及高效实施同步 SGD， 全面减少 Spark 上的通信，有效地向外扩展，以“大数据规模”执行数据分析。


  [1]: https://github.com/maxpumperla/elephas
  [2]: http://www.sukidesu.top/usr/uploads/2020/12/2540346532.gif
  [3]: https://github.com/yahoo/TensorFlowOnSpark
  [4]: https://github.com/cerndb/dist-keras
  [5]: https://github.com/horovod/horovod
  [6]: https://determined.ai/product/
  [7]: https://github.com/Angel-ML/angel